{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M2177.003100 Deep Learning <br> Assignment #4 Implementing Variational AutoEncoder - part1 MNIST data\n",
    "\n",
    "Copyright (C) Data Science Laboratory, Seoul National University. This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them. Written by Chaehun Shin, September 2020\n",
    "\n",
    "In this notebook, you will learn how to implement Variational AutoEncoder (VAEs) <br>\n",
    "The goal here is to build VAEs that draw a digit (MNIST data) <br> \n",
    "\n",
    "**Note**: certain details are missing or ambiguous on purpose, in order to test your knowledge on the related materials. However, if you really feel that something essential is missing and cannot proceed to the next step, then contact the teaching staff with clear description of your problem.\n",
    "\n",
    "### Submitting your work:\n",
    "<font color=red>**DO NOT clear the final outputs**</font> so that TAs can grade both your code and results.  \n",
    "Once you have done **all parts**, run the *CollectSubmission.sh* script with your **Student_ID** as input argument. <br>\n",
    "This will produce a zipped file called *[Your Student_ID].zip*. Please submit this file on ETL. &nbsp;&nbsp; (Usage: ./*CollectSubmission.sh* &nbsp; Student_ID)\n",
    "\n",
    "### Some helpful tutorials and references for assignment #4-1:\n",
    "- [1] Pytorch official tutorials. [[link]](https://pytorch.org/tutorials/)\n",
    "- [2] Stanford CS231n lectures. [[link]](http://cs231n.stanford.edu/)\n",
    "- [3] Kingma, Diederik P., and Max Welling. \"Auto-encoding variational bayes.\" arXiv preprint arXiv:1312.6114 (2013).\n",
    "- [4] Doersch, Carl. \"Tutorial on variational autoencoders.\" arXiv preprint arXiv:1606.05908 (2016).\n",
    "- [5] Kingma, Diederik P., and Max Welling. \"An Introduction to Variational Autoencoders.\" arXiv preprint arXiv:1906.02691 (2019)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Download and load MNIST datasets\n",
    "The MNIST datasets will be downloaded into the 'data/mnist' directory. If you want to change the directory the data is saved in, change 'mnist_data_dir' with where you want. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as T\n",
    "\n",
    "mnist_data_dir = './data/mnist'\n",
    "dataset = MNIST(root=mnist_data_dir,\n",
    "               transform=T.ToTensor(), train=True, download=True)\n",
    "print(dataset.train_data.shape)\n",
    "print(dataset.train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"1\"></a> 1. Building a network\n",
    "\n",
    "In this section, you will implement neural networks for <br>\n",
    "(1) encoder $q_\\phi(z \\mid x)$ to encode latent variable distribution from the image of the digit <br>\n",
    "(2) decoder $p_\\theta(x \\mid z)$ to decode the image distribution of the digit from the sample of latent variable distribution.<br>\n",
    "You can use some layer function implemented in **'torch.nn'** library (abbretivated as **nn**) or **'torch.nn.functional'** library (abbreviated as **F**) as you want.\n",
    "\n",
    "Just write the code in whatever way you find most clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time for an encoder. <br>\n",
    "It takes img_data, img_dim(should be 28\\*28\\*1=784 here), latent_dim(dimension of the z).<br>\n",
    "It should return parameters of the latent variable distribution with the dimension of latent_dim. <br>\n",
    "Because we model the latent variable distribution as multivariate Gaussian, we can make the distribution with only mean and covariance matrix. Also as we model each dimension of the latent variable as independent, covariance matrix becomes a diagonal matrix and we need only latent_dim number of elements for covariance matrix. <br>\n",
    "So we output 2 latent_dim dimension vectors from the encoder function implemented by neural network. **I recommend to use logvar not variance itself for stable training.**\n",
    "\n",
    "\n",
    "Maybe you can use two neural networks for mean and logvar vectors. However **it is recommended to use only one neural network with two last branches.**<br>\n",
    "For example, if you use 5 layer networks, first 4 layers are shared and there are two 5th layers each corresponding to mean and logvar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, img_dim=784, latent_dim=30):\n",
    "        super().__init__()\n",
    "        ################ ToDo ################\n",
    "        \n",
    "    def forward(self, imgs):\n",
    "        ################ ToDo ################\n",
    "        \n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time for a decoder model. <br>\n",
    "It takes sample of the latent variable distribution(z), latent_dim(dimension of the latent variable), and img_dim(28\\*28\\*1=784 here). It should return the reconstruction of the original image x_hat. <br>\n",
    "Decoder models the likelihood distributions and in here, we model each pixel as Bernoulli distribution(So we use binary cross entropy as loss function). So **you should use the sigmoid function to make the output as probability in [0, 1]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=30, img_dim=784):\n",
    "        super().__init__()\n",
    "        ################ ToDo ################\n",
    "        \n",
    "    def forward(self, z):\n",
    "        ################ ToDo ################\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we construct the VAEs with encoder and decoder.<br>\n",
    "This model rquires an implementation of reparameterization trick (which you need to implement) due to impossible differentiation of sampling.<br>\n",
    "\n",
    "### Reparameterization trick can be implemented as follows.\n",
    "Our Encoder outputs mean and variance of Guassian distrubiton as parameters of posterior distribution.<br>\n",
    "\n",
    "1. We sample epsilon form standard normal distribution with the size of latent dimension. <br>\n",
    "2. Then, we scale and shift epsilon by using variance and mean of posterior distrubiton.<br>\n",
    "\n",
    "Because sampling is out of graph, gradient can be flowed from loss to encoder and decoder. So we can train all networks jointly as you see in the forward function.\n",
    "\n",
    "If you want to sample from the VAEs, you just sample from the prior distribution and go trough the decoder, as you can see in the sample function implemented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, img_dim=784, latent_dim=10):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(img_dim, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, img_dim)\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "    def encode(self, imgs):\n",
    "        mu, logvar = self.encoder(imgs)\n",
    "        return mu, logvar\n",
    "    \n",
    "    def decode(self, z):\n",
    "        recon_imgs = self.decoder(z)\n",
    "        return recon_imgs\n",
    "        \n",
    "    def reparameterize(self, eps, mu, logvar):\n",
    "        ################ ToDo ################\n",
    "        \n",
    "    def forward(self, imgs):\n",
    "        mu, logvar = self.encode(imgs)\n",
    "        eps = torch.randn_like(mu)\n",
    "        z = self.reparameterize(eps, mu, logvar)\n",
    "        recon_imgs = self.decode(z)\n",
    "        return recon_imgs, mu, logvar\n",
    "    \n",
    "    def sample(self, num_samples=16):\n",
    "        device = next(self.parameters()).device\n",
    "        eps = torch.randn((num_samples, self.latent_dim)).to(device)\n",
    "        gen_imgs = self.decode(eps)\n",
    "        return gen_imgs        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"2\"></a> 2. Build a main part and train\n",
    "\n",
    "In this section, you will implement the main part (define the loss function in TODO part).\n",
    "Feel free to set the hyperparmeters and fill in the main part.\n",
    "Then run the code and check the model reconstructs a digit.\n",
    "When you are done, run the following to check your implementations.\n",
    "\n",
    "Be sure to define **batch size bigger than 16** (Because, we visualize 16 images per batch in training time). <br>\n",
    "You must show **at least three generated images** (At the beginning of ,in the midway of, at the end of training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter setting\n",
    "img_dim=784\n",
    "latent_dim=50\n",
    "\n",
    "batch_size = 64 # it should be larger than 16\n",
    "learning_rate = 1e-4\n",
    "total_iter = 50000\n",
    "\n",
    "log_freq = 10\n",
    "viz_freq = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "dataloader_iter = iter(dataloader)\n",
    "\n",
    "vae = VAE(img_dim, latent_dim).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(vae.parameters(), learning_rate)\n",
    "\n",
    "\n",
    "for it in range(total_iter):\n",
    "    try:\n",
    "        imgs, _ = next(dataloader_iter)\n",
    "    except:\n",
    "        dataloader_iter = iter(dataloader)\n",
    "        imgs, _ = next(dataloader_iter)\n",
    "        \n",
    "    imgs = imgs.view((-1, img_dim)).to(device)\n",
    "    recon_imgs, mu, logvar = vae(imgs)\n",
    "    \n",
    "    ################ ToDo ################\n",
    "    recon_loss = \n",
    "    kldiv_loss = \n",
    "    total_loss = (recon_loss + kldiv_loss)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (it+1) % log_freq == 0:\n",
    "        print(\"Iter: %05d/%d, Recon loss: %.4f, KL div loss: %.4f, Total loss: %.4f\"%(it+1, total_iter,\n",
    "                                                                                            recon_loss.data.item(),\n",
    "                                                                                            kldiv_loss.data.item(),\n",
    "                                                                                            total_loss.data.item()))\n",
    "        \n",
    "    if (it+1) % viz_freq == 0:\n",
    "        with torch.no_grad():\n",
    "            gen_imgs = vae.sample(16)\n",
    "        org_imgs = make_grid(imgs[:16, :].view((16, 1, 28, 28)), nrow=4).permute(1, 2, 0).cpu().detach().numpy()\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(org_imgs)\n",
    "        recon_imgs = make_grid(recon_imgs[:16].view((16, 1, 28, 28)), nrow=4).permute(1, 2, 0).cpu().detach().numpy()\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(recon_imgs)\n",
    "        gen_imgs = make_grid(gen_imgs[:16].view((16, 1, 28, 28)), nrow=4).permute(1, 2, 0).cpu().detach().numpy()\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(gen_imgs)\n",
    "            \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch] *",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
