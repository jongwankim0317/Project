{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M2177.003100 Deep Learning <br> Assignment #4 Implementing Generative Adversarial Nets - part2 MNIST data\n",
    "\n",
    "Copyright (C) Data Science Laboratory, Seoul National University. This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them. Written by Chaehun Shin, September 2020\n",
    "\n",
    "In this notebook, you will learn how to implement Generative Adversarial Networks (GANs) <br>\n",
    "The goal here is to build GANs that draw hand-written digits (MNIST data) <br> \n",
    "\n",
    "**Note**: certain details are missing or ambiguous on purpose, in order to test your knowledge on the related materials. However, if you really feel that something essential is missing and cannot proceed to the next step, then contact the teaching staff with clear description of your problem.\n",
    "\n",
    "### Submitting your work:\n",
    "<font color=red>**DO NOT clear the final outputs**</font> so that TAs can grade both your code and results.  \n",
    "Once you have done **all parts**, run the *CollectSubmission.sh* script with your **Student_ID** as input argument. <br>\n",
    "This will produce a zipped file called *[Your Student_ID].zip*. Please submit this file on ETL. &nbsp;&nbsp; (Usage: ./*CollectSubmission.sh* &nbsp; Student_ID)\n",
    "\n",
    "### Some helpful tutorials and references for assignment #4-2:\n",
    "- [1] Pytorch official tutorials. [[link]](https://pytorch.org/tutorials/)\n",
    "- [2] Stanford CS231n lectures. [[link]](http://cs231n.stanford.edu/)\n",
    "- [3] Goodfellow, Ian, et al. \"Generative adversarial nets.\" Advances in neural information processing systems. 2014.\n",
    "- [4] Mirza, Mehdi, and Simon Osindero. \"Conditional generative adversarial nets.\" arXiv preprint arXiv:1411.1784 (2014).\n",
    "- [5] Radford, Alec, Luke Metz, and Soumith Chintala. \"Unsupervised representation learning with deep convolutional generative adversarial networks.\" arXiv preprint arXiv:1511.06434 (2015)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Download and load MNIST datasets\n",
    "The MNIST datasets will be downloaded into the 'data/mnist' directory. If you want to change the directory the data is saved in, change 'mnist_data_dir' with where you want. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as T\n",
    "\n",
    "mnist_data_dir = './data/mnist'\n",
    "dataset = MNIST(root=mnist_data_dir,\n",
    "               transform=T.ToTensor(), train=True, download=True)\n",
    "print(dataset.train_data.shape)\n",
    "print(dataset.train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"1\"></a> 1. Building a network\n",
    "\n",
    "\n",
    "In this section, you will implement neural networks for <br>\n",
    "(1) generator model to draw a digit <br>\n",
    "(2) discriminator model to distinguish real images from generated images.<br>\n",
    "You can use some layer function implemented in **'torch.nn'** library (abbretivated as **nn**) or **'torch.nn.functional'** library (abbreviated as **F**) as you want.\n",
    "Just write the code in whatever way you find most clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time for a generator model.\n",
    "You can change anything including the argument if you need. Feel Free to implement it.<br>\n",
    "**(You should output the image as a range (0, 1) with Sigmoid function because we normalize the real images as a range (0, 1))**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=10, image_dim=1):\n",
    "        super().__init__()\n",
    "        ################ ToDo ################\n",
    "\n",
    "        \n",
    "    def forward(self, z):\n",
    "        ################ ToDo ################\n",
    "\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time for a discriminator model. Again, you can implement anything if you need. <br>\n",
    "**(You should output the probability of whether the input image of discriminator is real or not. It means that you use the Sigmoid function at the last layer to make the value being in range (0, 1))**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim=3):\n",
    "        super().__init__()\n",
    "        ################ ToDo ################\n",
    "\n",
    "        \n",
    "    def forward(self, img):\n",
    "        ################ ToDo ################\n",
    "\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"2\"></a> 2. Build a main part and train\n",
    "\n",
    "In this section, you will implement the main part (define criterion variable and D_loss/G_loss to train in TODO parts, you can also use the criterion variable).\n",
    "Feel free to set the hyperparmeters and fill in the main part.\n",
    "When you are done, run the following to check your implementations.\n",
    "In this section, you will implement the main part (define criterion variable and D_loss/G_loss to train in TODO parts).\n",
    "\n",
    "You must show **at least three generated images** (At the beginning of, in the midway of, at the end of training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter setting\n",
    "img_dim=1\n",
    "img_size = 28\n",
    "latent_dim = 100\n",
    "num_D_updates_per_G_update = 5\n",
    "\n",
    "batch_size = 128\n",
    "learning_rate = 1e-4\n",
    "total_iter = 50000\n",
    "\n",
    "log_freq = 10\n",
    "viz_freq = 200\n",
    "\n",
    "gen_num_samples = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "dataloader_iter = iter(dataloader)\n",
    "\n",
    "netG = Generator(latent_dim, img_dim).to(device)\n",
    "netD = Discriminator(img_dim).to(device)\n",
    "\n",
    "optimG = torch.optim.Adam(netG.parameters(), learning_rate)\n",
    "optimD = torch.optim.Adam(netD.parameters(), learning_rate)\n",
    "\n",
    "real_labels = torch.ones(batch_size).to(device)\n",
    "fake_labels = torch.zeros(batch_size).to(device)\n",
    "\n",
    "for it in range(total_iter):\n",
    "    \n",
    "    # train Discriminator\n",
    "    for _ in range(num_D_updates_per_G_update):\n",
    "        try:\n",
    "            real_imgs, _ = next(dataloader_iter)\n",
    "        except:\n",
    "            dataloader_iter = iter(dataloader)\n",
    "            real_imgs, _ = next(dataloader_iter)\n",
    "\n",
    "        real_imgs = real_imgs.to(device)\n",
    "\n",
    "        z = torch.randn((batch_size, latent_dim)).to(device)\n",
    "        fake_imgs = netG(z).detach()\n",
    "        \n",
    "        real_probs = netD(real_imgs).squeeze()\n",
    "        fake_probs = netD(fake_imgs).squeeze()\n",
    "\n",
    "        ################ ToDo ################\n",
    "        D_loss = \n",
    "        \n",
    "        optimD.zero_grad()\n",
    "        D_loss.backward()\n",
    "        optimD.step()\n",
    "      \n",
    "    # train the Generator\n",
    "    z = torch.randn((batch_size, latent_dim)).to(device)\n",
    "    fake_imgs = netG(z)\n",
    "        \n",
    "    fake_probs = netD(fake_imgs)\n",
    "\n",
    "    ################ ToDo ################\n",
    "    G_loss = \n",
    "\n",
    "    optimG.zero_grad()\n",
    "    G_loss.backward()\n",
    "    optimG.step()\n",
    "    \n",
    "    if (it+1) % log_freq == 0:\n",
    "        print(\"Iter: %05d/%d, Gen loss: %.4f, Dis loss: %.4f\"%(it+1, total_iter,\n",
    "                                                              D_loss.data.item(),\n",
    "                                                              G_loss.data.item()))\n",
    "    if (it+1) % viz_freq == 0:\n",
    "        z = torch.randn((gen_num_samples, latent_dim)).to(device)\n",
    "        with torch.no_grad():\n",
    "            gen_imgs = netG(z)\n",
    "        \n",
    "        gen_imgs = make_grid(gen_imgs, nrow=10).permute(1, 2, 0).cpu().detach().numpy()\n",
    "        plt.imshow(gen_imgs)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch] *",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
